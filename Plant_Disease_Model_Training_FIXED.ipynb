{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Plant Disease Recognition - Model Training (FIXED)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Step 1: Setup and Download Data",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "!wget -O \"dataset.zip\" \"https://data.mendeley.com/public-files/datasets/tywbtsjrjv/files/b4e3a32f-c0bd-4060-81e9-6144231f2520/file_downloaded\"\n\n!unzip -q /content/dataset.zip\n\n!pip install -q split-folders",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Step 2: Import Libraries and Define Constants",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport tensorflow as tf\nimport splitfolders\n\n# --- Configuration ---\nRAW_DATA_DIR = \"/content/Plant_leave_diseases_dataset_with_augmentation\"\nOUTPUT_DATA_DIR = \"/content/dataset\"\nTRAIN_DIR = \"/content/dataset/train\"\nVALIDATION_DIR = \"/content/dataset/val\"\nTEST_DIR = \"/content/dataset/test\"\n\nBATCH_SIZE = 32\n# CRITICAL FIX: Ensure image size is (160, 160)\nIMG_SIZE = (160, 160)\n# CRITICAL FIX: Shape must be (160, 160, 3) for RGB\nIMG_SHAPE = IMG_SIZE + (3,)\n\nINITIAL_EPOCHS = 6\nFINE_TUNE_EPOCHS = 10\nTOTAL_EPOCHS = INITIAL_EPOCHS + FINE_TUNE_EPOCHS\nFINE_TUNE_AT = 100",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Step 3: Split Data",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "splitfolders.ratio(RAW_DATA_DIR, output=OUTPUT_DATA_DIR, seed=1337, ratio=(.8, .1,.1))",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Step 4: Data Preprocessing",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "train_dataset = tf.keras.utils.image_dataset_from_directory(TRAIN_DIR,\n                                                                shuffle=True,\n                                                                batch_size=BATCH_SIZE,\n                                                                image_size=IMG_SIZE)\n\nvalidation_dataset = tf.keras.utils.image_dataset_from_directory(VALIDATION_DIR,\n                                                                      shuffle=True,\n                                                                      batch_size=BATCH_SIZE,\n                                                                      image_size=IMG_SIZE)\n\ntest_dataset = tf.keras.utils.image_dataset_from_directory(TEST_DIR,\n                                                               batch_size=BATCH_SIZE,\n                                                               image_size=IMG_SIZE)\n\nclass_names = train_dataset.class_names\nprint(f\"Found {len(class_names)} classes.\")\n\n# Configure dataset for performance\nAUTOTUNE = tf.data.AUTOTUNE\ntrain_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\nvalidation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\ntest_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Step 5: Build the Model",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "preprocess_input = tf.keras.applications.efficientnet.preprocess_input\n\n# Create the base model\nbase_model = tf.keras.applications.EfficientNetB4(\n    input_shape=IMG_SHAPE,  # This now correctly uses (160, 160, 3)\n    include_top=False,\n    weights='imagenet'\n)\n\nbase_model.trainable = False # Freeze the base\n\n# Build the full model\ninputs = tf.keras.Input(shape=IMG_SHAPE)\nx = preprocess_input(inputs)\nx = base_model(x, training=False)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\nx = tf.keras.layers.Dropout(0.2)(x)\noutputs = tf.keras.layers.Dense(len(class_names), activation='sigmoid')(x)\nmodel = tf.keras.Model(inputs, outputs)\n\n# Compile for feature extraction\nmodel.compile(optimizer=tf.keras.optimizers.Adam(),\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n              metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')])\n\nmodel.summary()",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Step 6: Train (Feature Extraction)",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "history = model.fit(train_dataset,\n                        epochs=INITIAL_EPOCHS,\n                        validation_data=validation_dataset)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Step 7: Fine-Tuning",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "base_model.trainable = True\n\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in base_model.layers[:FINE_TUNE_AT]:\n  layer.trainable = False\n\n# Re-compile the model for fine-tuning with a low learning rate\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), \n              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n              metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')])\n\nmodel.summary()\n\n# Continue training\nhistory_fine = model.fit(train_dataset,\n                         epochs=TOTAL_EPOCHS,\n                         initial_epoch=history.epoch[-1],\n                         validation_data=validation_dataset)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Step 8: Evaluate and Save",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "loss, accuracy = model.evaluate(test_dataset)\nprint('Test accuracy :', accuracy)\n\n# Save the new, correct model\nNEW_MODEL_NAME = \"plant_disease_model_V3.keras\"\nmodel.save(NEW_MODEL_NAME)\nprint(f\"Model saved as {NEW_MODEL_NAME}\")\n\n# Optional: Save to Google Drive\ntry:\n  from google.colab import drive\n  drive.mount('/content/drive')\n  model.save(f\"/content/drive/MyDrive/{NEW_MODEL_NAME}\")\n  print(f\"Model also saved to Google Drive: /content/drive/MyDrive/{NEW_MODEL_NAME}\")\nexcept Exception as e:\n  print(f\"Could not save to Google Drive: {e}\")",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    }
  ]
}